# Index of Recipes

| Database | Version | Task |
| -------- | ------- | ---- |
| [VoxCeleb](http://www.robots.ox.ac.uk/~vgg/data/voxceleb) | v1 | VoxCeleb1 Speaker Verification with x-Vectors |
| | v1.1 | VoxCeleb1 Speaker Verification with x-Vectors <br> using on-the-fly feature extraction and speech augmentation |
| | adv.v1 | Adversarial Attacks and Baseline Defenses on <br> x-Vector Speaker Verification <br> used in our InterSpeech 2020 paper|
| | adv.v1.1 | Adversarial Attacks and Baseline Defenses on <br> x-Vector Speaker Verification <br> where x-vector training is done using on-the-fly feature extaction <br> used in our InterSpeech 2020 paper|
| | adv.v2 | Classification and Detection of Adversarial Attacks in <br> Speaker Id. and Verification using <br> x-Vector style DNN to compute attack signatures <br> used in our InterSpeech 2021 paper |
| | vae.v1 | Evaluate Generative Models (VAE) |
| ------- | ------- | ---- |
| [sre19-cmn2](https://www.nist.gov/itl/iad/mig/nist-2019-speaker-recognition-evaluation) | v1 | NIST SRE19-CTS Tunisian Arabic using Kaldi x-Vectors |
| | v2 | SRE19-CTS Tunisian Arabic using PyTorch x-Vectors <br> It uses precomputed features |
| | v2.1 | SRE19-CTS Tunisian Arabic using PyTorch x-Vectors <br> It uses on-the-fly feat extraction and speech augmentation |
| ------- | ------- | ---- |
| [sre19-av-a](https://www.nist.gov/itl/iad/mig/nist-2019-speaker-recognition-evaluation) | v1 | NIST SRE19-AV Audio only using Kaldi x-Vectors |
| | v2 | SRE19-AV using PyTorch x-Vectors <br> It uses precomputed features (Unfinished)|
| | v2.1 | SRE19-AV using PyTorch x-Vectors <br> It uses on-the-fly feat extraction and speech augmentation |
| ------- | ------- | ---- |
| [sre19-av-v](https://www.nist.gov/itl/iad/mig/nist-2019-speaker-recognition-evaluation) | v0.1 | NIST SRE19-AV Face Recognition using <br> Insightface MX-Net Pretrained RetinaFace and ArcFace models <br> used in JHU-CLSP submission to SRE19 |
| | v0.2 | NIST SRE19-AV Face Recognition using <br> Fomaliu PyTorch Pretrained RetinaFace and ArcFace models <br> trying to replicate JHU-HLTCOE submission to SRE19 |
| ------- | ------- | ---- |
| [sre20-cts](https://www.nist.gov/publications/nist-2020-cts-speaker-recognition-challenge-evaluation-plan) | v1 | NIST SRE20-CTS recipe used by JHU-MIT team |
| ------- | ------- | ---- |
| [sre21-av-a](https://www.nist.gov/itl/iad/mig/nist-2021-speaker-recognition-evaluation-sre21) | v1.16k | NIST SRE21 Audio recipe used by JHU-MIT team <br> It usamples telephone data to 16kHz using SoX |
| | v1.8k | NIST SRE21 Audio recipe used by JHU-MIT team <br> It downsamples audio from video data to 8 kHz |
| ------- | ------- | ---- |
| [sre21-av-v](https://www.nist.gov/itl/iad/mig/nist-2021-speaker-recognition-evaluation-sre21) | v0.1 | NIST SRE21 Visual recipe used by JHU-MIT team <br> It uses Pretrained InsightFace embeddings in MX-Net |
| | v0.2 | NIST SRE21 Visual recipe used by JHU-MIT team <br> It uses Pretrained InsightFace embeddings in PyTorch |
| ------- | ------- | ---- |
| [sre21-av-v](https://www.nist.gov/itl/iad/mig/nist-2021-speaker-recognition-evaluation-sre21) | v1 | NIST SRE21 Audio-Visual fusion used by JHU-MIT team <br> It fuses the scores produced by sre21-av-a and sre21-av-v recipes |
| ------- | ------- | ---- |
| [voices_challenge](https://iqtlabs.github.io/voices/downloads/) | v1 | VOiCES challenge 2019 using x-vectors |
| ------- | ------- | ---- |
| [chime_spkdet](https://www.isca-speech.org/archive/Interspeech_2019/pdfs/2174.pdf) | v1 | Speaker Recognition Benchmark based on [CHiME](http://spandh.dcs.shef.ac.uk/chime_challenge/CHiME5/data.html) data |
| ------- | ------- | ---- |
| [CIFAR](https://www.cs.toronto.edu/~kriz/cifar.html) | v1 | CIFAR-10/100 Image classification task|
| ------- | ------- | ---- |
| [MNIST](http://yann.lecun.com/exdb/mnist/) | v1 | MNIST Handwritten digits classification task|
